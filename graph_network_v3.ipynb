{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dccebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from obspy import read\n",
    "from pyasdf import ASDFDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebed255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gml graph\n",
    "gml_file_path = \"GraphNoise/cumulative_network_new.gml\"\n",
    "graph = nx.read_gml(gml_file_path)\n",
    "print(\"gml loaded\")\n",
    "\n",
    "# Load csv file containing sac metadata\n",
    "csv_file_path = \"GraphNoise/updated_wikifile.csv\"\n",
    "csv_data = pd.read_csv(csv_file_path)\n",
    "print(\"csv loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c0de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_station(station, graph, sac_folder, output_file, overwrite=False, verbose=True):\n",
    "    # Handle file overwriting\n",
    "    if os.path.exists(output_file):\n",
    "        if overwrite:\n",
    "            os.remove(output_file)\n",
    "            if verbose:\n",
    "                print(f\"File '{output_file}' exists. Overwriting...\")\n",
    "        else:\n",
    "            raise FileExistsError(f\"File '{output_file}' already exists. Use overwrite=True to replace it.\")\n",
    "\n",
    "    # Create the ASDF file\n",
    "    asdf_ds = ASDFDataSet(output_file, compression=\"lzf\")\n",
    "\n",
    "    # Get connected nodes for the station\n",
    "    connected_nodes = list(graph.neighbors(station))\n",
    "    if verbose:\n",
    "        print(f\"Station '{station}' is connected to: {connected_nodes}\")\n",
    "\n",
    "    # Collect SAC file information for only the connected days\n",
    "    sac_files_added = []\n",
    "    dates = []\n",
    "    for connected_node in connected_nodes:\n",
    "        if graph.has_edge(station, connected_node):\n",
    "            edges = graph[station][connected_node]\n",
    "            if 'dates' in edges:\n",
    "                dates.extend(edges['dates'])\n",
    "            else:\n",
    "                print(f\"Warning: No 'dates' attribute for edge between {station} and {connected_node}.\")\n",
    "\n",
    "    # Keep only unique dates\n",
    "    unique_dates = sorted(set(dates))\n",
    "    \n",
    "    # Process SAC files for the target station\n",
    "    for date in unique_dates:\n",
    "        # Format the date to match SAC file naming convention\n",
    "        date_str = datetime.strptime(date, \"%Y_%m_%d\").strftime(\"%Y.%j\")\n",
    "        print(f\"Processing date: {date} (formatted: {date_str})\")\n",
    "\n",
    "        # Find SAC files for the target station\n",
    "        station_name = station.split(\"/\")[-1]  # Extract the station's folder name\n",
    "        sac_folder_path = os.path.join(sac_folder, station_name)\n",
    "        search_path = os.path.join(sac_folder_path, f\"*{date_str}*.sac\")\n",
    "        sac_files = glob.glob(search_path)\n",
    "        if not sac_files and verbose:\n",
    "            print(f\"No SAC files found for station: {station_name} on date: {date_str}.\")\n",
    "        else:\n",
    "            print(f\"Found SAC files for station: {station_name} on date: {date_str}: {sac_files}\")\n",
    "\n",
    "        # Add SAC files for the target station\n",
    "        for sac_file in sac_files:\n",
    "            try:\n",
    "                st = read(sac_file)\n",
    "                valid_tag = re.sub(r\"[^a-z0-9_]\", \"_\", f\"{st[0].stats.station}_{date_str}\".lower())\n",
    "                print(f\"Adding SAC file '{sac_file}' with tag '{valid_tag}'\")\n",
    "                asdf_ds.add_waveforms(sac_file, tag=valid_tag)\n",
    "                sac_files_added.append(sac_file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error adding SAC file '{sac_file}': {e}\")\n",
    "\n",
    "    # Process SAC files for connected nodes\n",
    "    for connected_node in connected_nodes:\n",
    "        connected_node_name = connected_node.split(\"/\")[-1]  # Extract the folder name\n",
    "        connected_node_folder = os.path.join(sac_folder, connected_node_name)\n",
    "        for date in unique_dates:\n",
    "            date_str = datetime.strptime(date, \"%Y_%m_%d\").strftime(\"%Y.%j\")\n",
    "            search_path = os.path.join(connected_node_folder, f\"*{date_str}*.sac\")\n",
    "            sac_files = glob.glob(search_path)\n",
    "            if not sac_files and verbose:\n",
    "                print(f\"No SAC files found for connected node: {connected_node_name} on date: {date_str}.\")\n",
    "            else:\n",
    "                print(f\"Found SAC files for connected node: {connected_node_name} on date: {date_str}: {sac_files}\")\n",
    "\n",
    "            # Add SAC files for the connected node\n",
    "            for sac_file in sac_files:\n",
    "                try:\n",
    "                    st = read(sac_file)\n",
    "                    valid_tag = re.sub(r\"[^a-z0-9_]\", \"_\", f\"{st[0].stats.station}_{date_str}\".lower())\n",
    "                    print(f\"Adding SAC file '{sac_file}' with tag '{valid_tag}'\")\n",
    "                    asdf_ds.add_waveforms(sac_file, tag=valid_tag)\n",
    "                    sac_files_added.append(sac_file)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error adding SAC file '{sac_file}': {e}\")\n",
    "\n",
    "    # Save the list of connected nodes\n",
    "    connected_nodes_array = np.array(connected_nodes, dtype=\"S\")\n",
    "    asdf_ds.add_auxiliary_data(\n",
    "        data=connected_nodes_array,\n",
    "        data_type=\"connections\",\n",
    "        path=station.replace(\".\", \"_\"),\n",
    "        parameters={\"description\": \"List of connected nodes for the station\"}\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Processing complete for station: {station}. File saved at {output_file}.\")\n",
    "        print(f\"Total SAC files added: {len(sac_files_added)}\")\n",
    "\n",
    "\n",
    "# Paths\n",
    "sac_folder_path = \"/home/ljiang14/sample_sac\"\n",
    "output_asdf_file = \"GraphNoise/DW_TOL_output_test6.h5\"\n",
    "\n",
    "# Station name\n",
    "station_name = \"DataDW/TOL\"\n",
    "\n",
    "# Process the single station\n",
    "process_single_station(station_name, graph, sac_folder_path, output_asdf_file, overwrite=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
